% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/runClassifiers.R
\name{runClassifiers}
\alias{runClassifiers}
\title{runClassifiers}
\usage{
runClassifiers(
  preProcess.obj,
  models = c("bag_mlp", "rand_forest", "svm_poly"),
  selector.recipes = c("boruta", "roc", "boruta"),
  tuning.method = "tune_grid",
  n = 5,
  v = 3,
  metric = "accuracy",
  nsim = 2,
  seed = 123
)
}
\arguments{
\item{preProcess.obj}{An object of class preProcess.}

\item{models}{A character vector specifying the models to be used.
Possible values are 'xgboost', 'bag_tree', 'lightGBM', 'pls', 'logistic',
'C5_rules', 'mars', 'bag_mars', 'mlp', 'bag_mlp', 'decision_tree',
'rand_forest', 'svm_linear', 'svm_poly', 'svm_rbf'.}

\item{selector.recipes}{A character vector specifying the selector recipes to be used.
Possible values are 'boruta', 'roc', 'infgain', 'mrmr', 'corr'.}

\item{tuning.method}{A character string specifying the tuning method to be used.
Possible values are 'tune_grid (default)', tune_race_anova',
tune_race_win_loss', 'tune_bayes', 'tune_sim_anneal'.}

\item{n}{An integer specifying the number of iterations for the tuning method.}

\item{v}{An integer specifying the number of folds for the cross-validation during the hyperparameters tuning.}

\item{metric}{A character string specifying the metric to be used for tuning.
Possible values are 'accuracy', 'roc_auc', 'sensitivity', 'specificity'.}

\item{nsim}{An integer specifying the number of simulations for the permutation-based VIP.}

\item{seed}{An integer specifying the seed for reproducibility.}
}
\value{
An object of class ensBP.
}
\description{
This function performs the ensemble of models using the ensBP approach.
}
\details{
The function performs the ensemble of models using the ensBP approach.
The function first filters the genes that are not annotated in the GO and KEGG databases.
Then, the function tunes and fits the models using the specified tuning method.
The function computes the variable importances for each model using the permutation-based VIP,
when the direct VIP computation fails.
}
\examples{
/dontrun{
rc <- runClassifiers(preProcess.obj, models = c("bag_mlp", "rand_forest", "svm_poly"),
                   selector.recipes = "boruta", tuning.method = "tune_grid", n = 5,
                   v = 3, metric = "accuracy", nsim = 2, seed = 123)}

}
