% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fun_valConsensus.R
\name{evaluate_one_side}
\alias{evaluate_one_side}
\title{Evaluate Clustering Results with Metric Orientation}
\usage{
evaluate_one_side(pred, truth, metric = metric)
}
\arguments{
\item{pred}{A vector of predicted cluster assignments (typically 0 and 1).}

\item{truth}{A vector of true class labels (must be coercible to factors with two levels).}

\item{metric}{A character string specifying the primary evaluation metric to use for orientation selection.
Must be one of \code{"Accuracy"}, \code{"Precision"}, \code{"Recall"}, or \code{"FScore"}.}
}
\value{
A named list containing:
\describe{
  \item{clusters}{A vector of predicted cluster assignments (after optimal orientation, as integers).}
  \item{Accuracy}{The accuracy of the clustering result.}
  \item{Precision}{The precision of the clustering result.}
  \item{Recall}{The recall of the clustering result.}
  \item{FScore}{The F1 score of the clustering result.}
}
}
\description{
Evaluates clustering results against true class labels using standard metrics.
Automatically checks both cluster label orientations (i.e., 0/1 or 1/0 assignment) and
selects the orientation with the best metric value.
}
\details{
Since unsupervised clustering labels (e.g., 0/1) may be assigned arbitrarily compared to
ground truth, this function evaluates both the predicted and inverted cluster assignments.
It then returns the set of metrics corresponding to the orientation that yields the
highest value for the selected metric.
}
\examples{
\dontrun{
true_labels <- factor(c(1, 0, 1, 0, 1))
predicted_clusters <- c(1, 0, 1, 0, 0)
evaluate_one_side(predicted_clusters, true_labels, metric = "Accuracy")
}

}
\seealso{
\code{\link[yardstick]{accuracy}}, \code{\link[yardstick]{precision}},
  \code{\link[yardstick]{recall}}, \code{\link[yardstick]{f_meas}}
}
